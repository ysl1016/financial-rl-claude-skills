# Phase 1 Colab ν…μ¤νΈ κ°€μ΄λ“

**μƒμ„±μΌ**: 2025-11-23  
**λ©μ **: Google Colabμ—μ„ Phase 1 μƒνƒ μμ΅΄μ  λ³΄μƒ ν™κ²½ ν…μ¤νΈ

---

## π“‹ μ¤€λΉ„λ¬Ό

1. Google κ³„μ • (Colab μ ‘μ†μ©)
2. μƒμ„±λ λ…ΈνΈλ¶: `phase1_state_dependent_test.ipynb`

---

## π€ μ‹¤ν–‰ λ°©λ²•

### Step 1: λ…ΈνΈλ¶ μƒμ„±

λ΅μ»¬μ—μ„ μ‹¤ν–‰:
```bash
cd /Users/ihyunseo/Projects/financial-rl-claude-skills/colab_notebooks
python3 phase1_state_dependent_test.py
```

μ¶λ ¥:
```
β“ Notebook created: phase1_state_dependent_test.ipynb
```

### Step 2: Colab μ—…λ΅λ“

1. **Colab μ ‘μ†**
   - https://colab.research.google.com/

2. **λ…ΈνΈλ¶ μ—…λ΅λ“**
   - File β†’ Upload notebook
   - `phase1_state_dependent_test.ipynb` μ„ νƒ

3. **GPU μ„¤μ •** (μ„ νƒμ‚¬ν•­)
   - Runtime β†’ Change runtime type
   - Hardware accelerator: GPU (T4)

### Step 3: μ‹¤ν–‰

**μ „μ²΄ μ‹¤ν–‰**:
- Runtime β†’ Run all

**μ…€λ³„ μ‹¤ν–‰**:
1. β… Mount Drive (μ„ νƒμ‚¬ν•­)
2. β… Install Dependencies
3. β… Define Environment
4. β… Create Test Data
5. β… Test 1: Reward Differentiation
6. β… Test 2: Action Balance
7. β… Visualization
8. β… Summary

---

## π“ μμƒ κ²°κ³Ό

### Test 1: Reward Differentiation

```
γ€Buy Action in Different Conditionsγ€‘
  Buy in Oversold (RSI=25): Reward = 5.2186
  Buy in Overbought (RSI=75): Reward = -2.7814
  Buy in Neutral (RSI=50): Reward = 1.2186

  Validation:
  β… Buy rewards correctly differentiated!
     Oversold (5.22) > Neutral (1.22) > Overbought (-2.78)

γ€Sell Action in Different Conditionsγ€‘
  Sell in Overbought (RSI=75): Reward = 5.0471
  Sell in Oversold (RSI=25): Reward = -2.9529
  Sell in Neutral (RSI=50): Reward = 1.0471

  Validation:
  β… Sell rewards correctly differentiated!
     Overbought (5.05) > Neutral (1.05) > Oversold (-2.95)
```

### Test 2: Action Balance

```
γ€Oversold Region (RSI=25)γ€‘
  Hold: -0.4529
  Buy:  5.2186
  β… Buy > Hold in oversold region

γ€Overbought Region (RSI=75)γ€‘
  Hold: -0.4529
  Sell: 5.0471
  β… Sell > Hold in overbought region
```

### Visualization

μƒμ„±λλ” κ·Έλν”„:
1. **Buy Reward vs RSI**: RSI κ°μ† μ‹ Buy λ³΄μƒ μ¦κ°€
2. **Sell Reward vs RSI**: RSI μ¦κ°€ μ‹ Sell λ³΄μƒ μ¦κ°€
3. **Buy vs Sell Comparison**: κµμ°¨μ  ν™•μΈ
4. **Summary Table**: λ³΄μƒ κµ¬μ΅° μ”μ•½

---

## π― μ„±κ³µ κΈ°μ¤€

λ¨λ“  ν…μ¤νΈ ν†µκ³Ό:
- β… Buy: Oversold > Neutral > Overbought
- β… Sell: Overbought > Neutral > Oversold
- β… Buy > Hold (in oversold)
- β… Sell > Hold (in overbought)

---

## π’Ύ κ²°κ³Ό μ €μ¥

**Drive μ €μ¥ κ²½λ΅**:
```
/content/drive/MyDrive/financial-rl-trading/phase1_results/
β”β”€β”€ reward_structure.png  # λ³΄μƒ κµ¬μ΅° μ‹κ°ν™”
```

---

## β οΈ λ¬Έμ  ν•΄κ²°

### λ¬Έμ  1: Drive λ§μ΄νΈ μ‹¤ν¨
```python
# Cell 2 μ¬μ‹¤ν–‰
from google.colab import drive
drive.mount('/content/drive')
```

### λ¬Έμ  2: ν¨ν‚¤μ§€ μ„¤μΉ μ¤λ¥
```python
# Cell 3 μ¬μ‹¤ν–‰
!pip install --upgrade gym numpy pandas matplotlib seaborn
```

### λ¬Έμ  3: λ©”λ¨λ¦¬ λ¶€μ΅±
- Runtime β†’ Factory reset runtime
- λ‹¤μ‹ μ‹¤ν–‰

---

## π“ λ…ΈνΈλ¶ κµ¬μ΅°

| Cell | λ‚΄μ© | μ†μ” μ‹κ°„ |
|------|------|-----------|
| 1 | Title & Overview | - |
| 2 | Mount Drive | 10μ΄ |
| 3 | Install Dependencies | 30μ΄ |
| 4 | Define Environment | 5μ΄ |
| 5 | Create Test Data | 5μ΄ |
| 6 | Test 1: Differentiation | 10μ΄ |
| 7 | Test 2: Balance | 10μ΄ |
| 8 | Visualization | 20μ΄ |
| 9 | Summary | - |

**μ΄ μ†μ” μ‹κ°„**: μ•½ 2λ¶„

---

## π”„ λ‹¤μ λ‹¨κ³„

ν…μ¤νΈ μ„±κ³µ ν›„:

1. **100 Episodes ν•™μµ**
   - κΈ°μ΅΄ μ—μ΄μ „νΈ μ‚¬μ©
   - StateDependentRewardEnv μ μ©
   - λ©ν‘: Alpha > 0%

2. **Phase 2 μ§„ν–‰**
   - GRPO Agent κµ¬ν„
   - Critic μ κ±°
   - κ·Έλ£Ή μƒν”λ§

---

**μ‘μ„±μΌ**: 2025-11-23 19:05  
**λ¬Έμ**: Phase 1 ν…μ¤νΈ κ²°κ³Ό κ³µμ  μ‹ μ¤ν¬λ¦°μƒ· μ²¨λ¶€
